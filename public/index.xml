<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mike&#39;s Notebook</title>
    <link>/</link>
    <description>Recent content on Mike&#39;s Notebook</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Sep 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Introducing echor</title>
      <link>/2018/09/24/introducing-echor/</link>
      <pubDate>Mon, 24 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/24/introducing-echor/</guid>
      <description>The U.S. Environmental Protection Agency (EPA) provides access to facility and compliance information for registered permit holders under the Clean Air Act, Clean Water Act. The primary way for non-governmental entities to obtain this data is through the EPA Environmental and Compliance History Online (ECHO) website. Data is housed under “media-specific” programs. Relevant to this post, the National Pollutant Discharge Elimination Systems (NPDES) maintains data on pollutant discharges to waterways and the Air Facility Service (AFS) maintain data on emission to air.</description>
    </item>
    
    <item>
      <title>Binomial Test for Water Quality Compliance</title>
      <link>/2018/03/26/binomial-test-for-water-quality-compliance/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/26/binomial-test-for-water-quality-compliance/</guid>
      <description>In the previous post, I used a geometric mean to assess water quality compliance. According to EPA guidance, this is appropriate for assessing bacteria levels in water bodies. For other conventional parameters, we can determine compliance when a standards violation is unlikely to occur more than 10% of the time. Using EPA guidance, we have both a test statistic (proportion of exceedances) and rejection region (&amp;gt;10%). We assume that each water quality sample is a sample from the population that represents the water body with unknown probability (\(p\)) of exceeding the criterion.</description>
    </item>
    
    <item>
      <title>Date-based rolling functions</title>
      <link>/2018/03/04/date-based-rolling-functions/</link>
      <pubDate>Sun, 04 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/04/date-based-rolling-functions/</guid>
      <description>States are responsible for water quality assessments that ensure waterbodies comply with designated uses under Section 305(b) of the Clean Water Act. Waterbodies that do not meet applicable standards are listed on the Section 303(d) list, which requires state establish a Total Maximum Daily Load (TMDL) for pollutants responsible for impairement.
For conventional parameters, the current guidance from EPA requires that a waterbody be listed when greater than 10% of samples exceed the numeric criteria.</description>
    </item>
    
    <item>
      <title>txwater retweets</title>
      <link>/2018/02/21/txwater-retweets/</link>
      <pubDate>Wed, 21 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/02/21/txwater-retweets/</guid>
      <description>Let’s find out the retweet relationships for #txwater twitter users. I’m going to use the R recipes by Bob Rudis in 21 Recipes for Mining Twitter Data with rtweet.
Extract the originlibrary(rtweet)library(tidyverse)txwater &amp;lt;- search_tweets(&amp;quot;#txwater&amp;quot;, n=1000)output &amp;lt;- filter(txwater, retweet_count &amp;gt; 0) %&amp;gt;% select(text, mentions_screen_name, retweet_count) %&amp;gt;% mutate(text = substr(text, 1, 30)) %&amp;gt;% unnest()as_tibble(output)## # A tibble: 290 x 3## text retweet_count mentions_screen_name## &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; ## 1 RT @jeremybmazur: Corpus Chris 1 jeremybmazur ## 2 RT @twdb_kathleen: Mtg w/ City 1 twdb_kathleen ## 3 Mtg w/ City of Mason Mayor Bre 1 twdb ## 4 Corpus Christi, recognizing th 1 &amp;lt;NA&amp;gt; ## 5 Enjoyed mtg w/ @CityofLlano Ma 1 CityofLlano ## 6 Enjoyed mtg w/ @CityofLlano Ma 1 twdb ## 7 Dr.</description>
    </item>
    
    <item>
      <title>Retrieve EPA ECHO Data in R</title>
      <link>/2018/01/03/retrieve-epa-echo-data-in-r/</link>
      <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/03/retrieve-epa-echo-data-in-r/</guid>
      <description>EPA’s ECHO website is a useful tool for obtaining wastewater discharge data, in the form of Discharge Monitoring Reports (DMR). These DMRs provide the reported monitoring data from permitted dischargers in the form of effluent quantity and quality. These are useful data for water quality modeling, load allocations, and watershed characterization. However, downloading from the website is tedious at best, requiring clicking through multiple screens one permit at a time.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Sat, 30 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>I am an early career research professional specializing in water science and policy. I leverage spatial and data analytic tools that provide effective visual and written communication to bridge gaps between policy, science, and the public. Currently as a researcher at the Texas Water Resources Institute, I primarily lead projects aimed at improving surface water quality in coordination with state and local stakeholders. Primary research interests include (1) watershed based planning and sustainability, (2) environmental data visualization and communication, and (3) local and regional water and energy planning.</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>/slides/</link>
      <pubDate>Sat, 30 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/slides/</guid>
      <description>Downloading EPA ECHO data with echor
FDC and LDC Development in R</description>
    </item>
    
    <item>
      <title>Time-series decomposition and trend analysis in Python</title>
      <link>/2015/08/01/simple-time-series-trend-analysis/</link>
      <pubDate>Sat, 01 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>/2015/08/01/simple-time-series-trend-analysis/</guid>
      <description>There are a number of methods to accomplish time-series decompositions in R, including the decompose and STL commands.
I haven&amp;rsquo;t come across a seasonal decomposition method in Python comparable to R&amp;rsquo;s STL. However, statsmodels 0.6 added a naive seasonal decomposition method similar to R&amp;rsquo;s decompose that is not as powerful as the LOESS method used in STL. Let&amp;rsquo;s run through an example:
import urllib2 import datetime as datetime import pandas as pd import statsmodels.</description>
    </item>
    
  </channel>
</rss>